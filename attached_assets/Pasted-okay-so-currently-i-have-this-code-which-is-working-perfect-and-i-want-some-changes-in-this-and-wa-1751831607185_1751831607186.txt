okay,

so currently i have this code which is working perfect and i want some changes in this and want to switch from stearmlit to a full fledge react app which is very responsive, first you understand the logic and then i'll tell what all components and feature i need in react app, the base is this file:

import streamlit as st
import os
import pandas as pd
from io import BytesIO
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain.embeddings import HuggingFaceEmbeddings
import tempfile
import re
import time
import hashlib
import pdfplumber
import traceback
import shutil
import logging

# Set up logging to file
logging.basicConfig(
    filename="app.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# Initialize session state
if "df" not in st.session_state:
    st.session_state.df = None
if "file_hash" not in st.session_state:
    st.session_state.file_hash = None

# Load environment variables
load_dotenv()
groq_api_key = os.getenv('GROQ_API_KEY')
os.environ["GOOGLE_API_KEY"] = os.getenv("GOOGLE_API_KEY")

st.set_page_config(page_title="📄 RFP Automated", layout="centered")
st.title("📄 RFP Automated Answer Generator")

# Prompt Template
prompt = ChatPromptTemplate.from_template(
"""
You are an expert in compliance and policy enforcement in Netradyne. Answer the question strictly based on the knowledge in the provided documents. 
Your response should be clear, authoritative, and focused solely on providing the most relevant and accurate answer.
Avoid mentioning the documents, sections, or any sources. Do not include the question or any prefixes in your response. Just provide the answer.
If the context does not contain relevant information, respond with: "I’m sorry, I don’t have enough information to answer this question"
If the answer to the question is a direct "YES" or "NO," provide a concise explanation of the reason for that answer, based on the context.
For all other cases, provide a detailed and accurate response based on the context.

<context>
{context}
</context>

Question: {input}
"""
)

# Helper function for retrying API calls
def invoke_with_retry(llm, input_text, max_retries=3, delay=5):
    for attempt in range(max_retries):
        try:
            response = llm.invoke(input_text)
            return response
        except Exception as e:
            if attempt < max_retries - 1:
                logger.warning(f"Attempt {attempt + 1} failed: {e}. Retrying in {delay} seconds...")
                time.sleep(delay)
            else:
                logger.error(f"All {max_retries} attempts failed: {e}\n{traceback.format_exc()}")
                raise e

# Vector Store Setup
@st.cache_resource
def load_vectorstore():
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    index_path = "faiss_index"
    try:
        if os.path.exists(index_path):
            vectors = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)
            test_query = "test"
            test_embedding = embeddings.embed_query(test_query)
            if len(test_embedding) != vectors.index.d:
                logger.warning(f"Dimension mismatch: Embedding dim={len(test_embedding)}, Index dim={vectors.index.d}. Rebuilding index.")
                shutil.rmtree(index_path)
                raise ValueError("Dimension mismatch, rebuilding index.")
            logger.info(f"Loaded FAISS index with {len(vectors.index_to_docstore_id)} documents")
        else:
            raise FileNotFoundError("No FAISS index found")
    except (ValueError, FileNotFoundError):
        loader = PyPDFDirectoryLoader("./docs")
        docs = loader.load()
        logger.info(f"Loaded {len(docs)} documents from ./docs")
        if not docs:
            st.error("No documents found in ./docs directory. Please add PDFs.")
            st.stop()
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        final_documents = text_splitter.split_documents(docs)
        logger.info(f"Split into {len(final_documents)} chunks")
        vectors = FAISS.from_documents(final_documents, embeddings)
        vectors.save_local(index_path)
        logger.info(f"Created new FAISS index with {len(vectors.index_to_docstore_id)} documents")
    return vectors.as_retriever(search_kwargs={"k": 3})

@st.cache_resource
def setup_chain():
    retriever = load_vectorstore()
    llm = ChatGroq(groq_api_key=groq_api_key, model_name="llama3-8b-8192")
    doc_chain = create_stuff_documents_chain(llm, prompt)
    def custom_retrieval_chain(query):
        try:
            logger.info(f"Processing query: {query['input'][:50]}...")
            retrieved = retriever.get_relevant_documents(query['input'])
            context = "\n".join(doc.page_content[:300] for doc in retrieved)
            logger.info(f"Retrieved context length: {len(context)} characters")
            result = doc_chain.invoke({'context': context, 'input': query['input']})
            return {'context': retrieved, 'answer': result}
        except Exception as e:
            logger.error(f"Retrieval chain error: {e}\n{traceback.format_exc()}")
            raise e
    return custom_retrieval_chain, llm

# Test API connectivity
retrieval_chain, llm = setup_chain()
try:
    response = invoke_with_retry(llm, "Test query")
    logger.info(f"API Test Response: {response.content}")
except Exception as e:
    st.error(f"Groq API Test Failed after retries: {type(e).__name__}: {str(e)}")
    st.stop()

# PDF Question Extractor
@st.cache_data
def extract_questions_from_pdf(uploaded_file):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.read())
        tmp_file_path = tmp_file.name
    questions = []
    try:
        with pdfplumber.open(tmp_file_path) as pdf:
            full_text = ""
            for page in pdf.pages:
                text = page.extract_text()
                if text:
                    full_text += text + "\n"
            lines = full_text.splitlines()
            merged_text = " ".join(line.strip() for line in lines if line.strip())
            questions = re.split(r"\?\s+", merged_text)
            questions = [q.strip() + "?" for q in questions if len(q.strip()) > 10]
            logger.info(f"Extracted {len(questions)} questions: {questions[:5]}")
    finally:
        os.unlink(tmp_file_path)
    return questions

# File Hashing
def hash_file(uploaded_file):
    hasher = hashlib.sha256()
    hasher.update(uploaded_file.read())
    uploaded_file.seek(0)
    return hasher.hexdigest()

# Question Processing with Caching
@st.cache_data
def process_question(question, _hash=None):
    if not isinstance(question, str) or pd.isna(question) or not question.strip():
        logger.warning("Invalid question detected")
        return "No question provided."
    question_hash = hashlib.sha256(question.encode()).hexdigest()
    for attempt in range(3):
        try:
            result = retrieval_chain({'input': question})
            logger.info(f"Processed question: {question[:50]}... Answer: {result['answer'][:50]}...")
            return result['answer']
        except Exception as e:
            error_msg = f"{type(e).__name__}: {str(e)}"
            logger.warning(f"Error on attempt {attempt + 1} for question '{question[:50]}...': {error_msg}")
            if "rate_limit_exceeded" in str(e).lower() and attempt < 2:
                time.sleep(2 * (attempt + 1))
                continue
            # Fallback to direct LLM call
            try:
                input_text = prompt.format(context="No context available", input=question)
                response = invoke_with_retry(llm, input_text)
                logger.info(f"Fallback for question: {question[:50]}... Answer: {response.content[:50]}...")
                return response.content
            except Exception as e2:
                error_msg2 = f"{type(e2).__name__}: {str(e2)}"
                logger.error(f"Fallback error after retries: {error_msg2}\n{traceback.format_exc()}")
                return f"Error: {error_msg2}"

# Main Logic
input_type = st.radio("📁 Choose input type", ("Excel", "PDF"))
if input_type == "Excel":
    uploaded_file = st.file_uploader("📤 Upload Excel (must have a 'Question' column)", type=["xlsx"])
else:
    uploaded_file = st.file_uploader("📤 Upload PDF containing questions", type=["pdf"])

if uploaded_file is not None:
    file_hash = hash_file(uploaded_file)
    if "file_hash" not in st.session_state or st.session_state.file_hash != file_hash:
        st.session_state.df = None
        st.session_state.file_hash = file_hash
        logger.info(f"New file uploaded, resetting state. Hash: {file_hash}")

    if input_type == "Excel":
        try:
            df = pd.read_excel(uploaded_file)
            if "Question" not in df.columns:
                st.error("❌ Excel must contain a column named 'Question'")
                st.stop()
            questions = df["Question"].tolist()
            logger.info(f"Loaded {len(questions)} questions from Excel")
        except Exception as e:
            st.error(f"Error reading Excel file: {str(e)}")
            st.stop()
    else:
        try:
            questions = extract_questions_from_pdf(uploaded_file)
            df = pd.DataFrame({"Question": questions})
            logger.info(f"Loaded {len(questions)} questions from PDF")
        except Exception as e:
            st.error(f"Error processing PDF file: {str(e)}")
            st.stop()

    if st.button("⚡ Generate Responses"):
        with st.spinner("⏳ Generating answers..."):
            if st.session_state.df is None:
                answers = [process_question(q) for q in questions]
                st.session_state.df = pd.DataFrame({
                    "Question": questions,
                    "Answer": answers,
                    "Accepted": [False] * len(questions)
                })
                logger.info(f"Initialized DataFrame with {len(questions)} questions and answers")

    if st.session_state.df is not None:
        st.header("Review Responses")
        df = st.session_state.df
        first_unaccepted = df[~df['Accepted']].index.min() if not df['Accepted'].all() else None

        for index, row in df.iterrows():
            is_accepted = row['Accepted']
            is_first_unaccepted = index == first_unaccepted
            with st.container():
                st.markdown(f'<div id="question_{index}">', unsafe_allow_html=True)
                with st.expander(f"Question {index + 1}: {row['Question']}", expanded=is_first_unaccepted and not is_accepted):
                    st.markdown(f"**Answer:** {row['Answer']}")
                    col1, col2 = st.columns(2)
                    with col1:
                        if not is_accepted and st.button("✅ Accept", key=f"accept_{index}"):
                            st.session_state.df.at[index, 'Accepted'] = True
                            logger.info(f"Accepted answer for question {index + 1}")
                            st.rerun()
                    with col2:
                        if not is_accepted and st.button("🔄 Regenerate", key=f"regenerate_{index}"):
                            new_answer = process_question(row['Question'])
                            st.session_state.df.at[index, 'Answer'] = new_answer
                            st.session_state.df.at[index, 'Accepted'] = False
                            logger.info(f"Regenerated answer for question {index + 1}")
                            st.rerun()
                st.markdown('</div>', unsafe_allow_html=True)

        if first_unaccepted is not None:
            st.markdown(
                f"""
                <script>
                document.getElementById('question_{first_unaccepted}').scrollIntoView({{behavior: 'smooth'}});
                </script>
                """,
                unsafe_allow_html=True
            )

        if all(df['Accepted']):
            output = BytesIO()
            df[['Question', 'Answer']].to_excel(output, index=False, engine='xlsxwriter')
            output.seek(0)
            st.download_button(
                label="📥 Download Final Responses",
                data=output,
                file_name="answered_questions.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            st.info("Please review all responses to download the file.")
    else:
        st.info("Please click 'Generate Responses'.")
else:
    st.info("Please upload a file to proceed.")